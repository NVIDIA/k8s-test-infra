# Default values for gpu-mock.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Namespace to deploy into
namespace:
  create: true
  name: gpu-mock

# Mock driver configuration
mockDriver:
  enabled: true
  image:
    repository: local/gpu-mockctl
    tag: dev
    pullPolicy: IfNotPresent
  
  # Number of mock GPUs to create (used in default mode)
  gpuCount: 8
  
  # Mock GPU model (used in default mode)
  gpuModel: "NVIDIA A100-SXM4-40GB"
  
  # Mock GPU architecture (used in default mode)
  # Options: dgxa100 (default), h100, h200, b200 (when available)
  architecture: dgxa100
  
  # Resources for the mock driver pod
  resources:
    requests:
      cpu: 10m
      memory: 10Mi
    limits:
      cpu: 100m
      memory: 50Mi
  
  # Node selector for mock driver deployment
  nodeSelector: {}
  
  # Tolerations for mock driver deployment
  tolerations:
    - operator: Exists

# NVIDIA Container Toolkit configuration
containerToolkit:
  # Enable/disable the container toolkit deployment
  enabled: true
  
  image:
    repository: nvcr.io/nvidia/k8s/container-toolkit
    tag: v1.14.5-ubi8
    pullPolicy: IfNotPresent
  
  # Container runtime to configure (docker, containerd, crio)
  runtime: containerd
  
  # RuntimeClass configuration
  runtimeClass:
    create: true
    name: nvidia
  
  # Resources for the toolkit pod
  resources:
    requests:
      cpu: 10m
      memory: 50Mi
    limits:
      cpu: 100m
      memory: 100Mi
  
  # Node selector for toolkit deployment
  nodeSelector: {}
  
  # Only deploy on nodes with mock driver
  requireMockDriver: true

# Common configuration
global:
  # Image pull secrets
  imagePullSecrets: []
  
  # Security context for privileged operations
  securityContext:
    privileged: true
    runAsUser: 0
  
  # Service account configuration
  serviceAccount:
    create: true
    annotations: {}
  
  # RBAC configuration for node labeling
  rbac:
    create: true

# Node labeling configuration
nodeLabeling:
  # Apply nvidia.com/gpu.present=true label
  gpuPresent: true
  
  # Apply feature.node.kubernetes.io/pci-10de.present=true label
  pciPresent: true

# CDI (Container Device Interface) configuration
cdi:
  # Enable CDI spec mode (if disabled, uses default dgxa100 mode)
  enabled: false
  
  # Option 1: Reference existing ConfigMap with CDI spec
  # The ConfigMap should have a key "spec.yaml" containing the CDI spec
  configMapName: ""
  
  # Option 2: Inline CDI spec (embedded in Helm values)
  # Leave empty to use ConfigMap or default mode
  inlineSpec: ""
  
  # Override architecture detection from CDI spec
  # Leave empty to auto-detect from CDI spec annotations
  architectureOverride: ""

# Development/debugging options
debug:
  # Enable debug logging
  enabled: false
  
  # Keep failed pods for debugging
  keepFailedPods: false
